1) This application can have its uses extended beyond Amazon to gather a plethora of useful data. You can use node and express to directly communicate to webpages that exist on the internet.. not just files existing in a directory. It is accomplished with the following code...

var express = require('express');
var path = require('path');
var app = express();
var request = require('request');
var cheerio = require('cheerio');
var fs = require('fs');
var port = whatever port you want .. 8080, 1337 as long as it is a usable port.

var url = whatever url you're trying to scrape data from

request(url,(err,res,body) => {
  var $ = cherrio.load(body);
  whatever things you want to scrape here..
}

this is the general idea of how to communicate with numerous webpages that you can customize searches for.


2) This can be used for products beyond books such as houses listed on real estate pages, prices of products on various retailers etc. This could effectively allow for comprehensive price comparison of many web services and retailer products. Clients who desire this type of data and price comparison can pay for companies such as Datafinity to harvest the relevant data they need for research, or possibly to build their own website with the data they want. Think bizrate, shopbot, or orbitz. The potential is limitless with data extraction.

3) This depends on what timeframe determines reasonable. This can be subjective to the person. I could parse 2 million books by further pursusing my algorithm that I had been creating this takes into account not only speed (not phenomenal speed), but also space efficiency. If you're going for a pure time efficiency approach with no regard for space, you could create some sort of algorithm that sorts the data into a datastructure for faster lookups, such as an object. If you can accomplish organizing the desired data into keys known ahead of time, you can increase speed efficiency by not having to iterate through a collection as much. I have yet to explore the possibility of using other datastructures such as linked lists, but they may hold some promise as well. 

note: The algorithm I proposed that makes a compromise of both would use a binary decision tree to sort things before ogranizing them to save space.


The following below is some pseudo code I was writing for determining how to work out space efficiency and still save somewhat on time. I have put this here in the event that I'm questioned about this in person. It no longer uses an array as a datastructure, but rather an object. It started as an array for the purpose of visually recognizing patterns.

// // const uh = 60; 

// // const limit = 10;

// // const thing1 = [ 1, 1, 1, 1, 1, 1, 2, 2, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 5 ];
// // vs
// const thign2 = { 
//   1: 6,
//   2: 2,
//   3: 3,
//   4: 4,
//   5: 4
// }

// // // [] [] [] [] [] []

// // // 1) Check the limit
// // // 2) Separate all the numbers that the limit will % 0 from those that wont.
// // // 3) So now we have [1,1,1,1,1,1]  [2,2]  [5,5,5,5] and..
// // // 4)                [3,3,3]  [4,4,4,4]
// // // 5) 
                    
                                      Books
                                        |
                                /               \
                  Whole numbers              non-whole
                      |                          |
                       
            /             \                  /        \
        lim % num == 0      else         sums whole   else
                    


5 * 4 = 20
20% 10 = 0  it's 0, so divide 2 by 2. Two boxes are needed

4 * 4 = 16
16%10 = 6 
so 4 + 2 = 6 you math the 4's and 2's

2 * 2 = 4
4 % 10 = 4 
so 1 + 3 = 4 you match the 1;s and 3's













