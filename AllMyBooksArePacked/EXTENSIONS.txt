1. For domains beyond Amazon.com, you would have to write a separate grab method for each domain. For example, the Crawler.grab_book would be renamed Crawler.grab_book_from_amazon and you would have more methods based on domain and product. The Crawler.grab_page function could be expanded to return the Nokogiri HTML Object and the domain of the page (maybe using image (logo) recognition or you can scan for words in H1 elements against a list of domain names that you have methods for). This could then be passed to a helper method which would call the proper method based on the domain returned from the Crawler.grab_page method. 

2. For products, you will have to create grab method for each type of product. I looked through other Amazon products and even though they are close to having the same css selctors, it's not quite the same. Plus you might want to have different properties based on product. As with the domain, you would expand the Crawler.grab_page function to return the Nokogiri HTML Object, domain, and the product. And then expand the helper function to call the proper grab_<blank>_from_<blank> function on your Nokogiri HTML Object.

3. This problem will become harder if you try to minimize boxes along with time. I used the first fit decreasing algorithm to sort the books into boxes which is in polynomial time. This doesn't minimize the boxes but it is a close approximation. I assume your weight split is greater than the largest book shipping weight. You can use the first fit method without sorting and your answer will be faster but less acurate. 